# app.py ‚Äî Production-ready SOC dashboard with intelligent CSV processing and enhanced analytics
import os
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
from attack_helper import (
    normalize_columns,
    mark_country_high_risk,
    mark_multiple_attempts,
    mark_ddos_like,
    validate_csv_structure,
)
from anomaly_detection import assign_risk_levels, generate_threat_intelligence

def _norm(p, n):
    import numpy as np
    p = np.asarray(p, dtype=float).ravel()
    if p.size != n:
        p = np.resize(p, n)
    p[~np.isfinite(p)] = 0
    p[p < 0] = 0
    s = p.sum()
    return (np.ones(n)/n) if s <= 0 else (p / s)


# Page configuration
st.set_page_config(
    page_title="SOC AI Threat Intelligence Platform",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for professional appearance
# Custom CSS for professional appearance with removed white spaces
st.markdown("""
<style>
    /* Remove default padding and margins */
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 100%;
    }
    
    /* Remove header padding */
    header[data-testid="stHeader"] {
        height: 0px;
        display: none;
    }
    
    /* Remove footer */
    footer {
        display: none;
    }
    
    /* Remove sidebar padding */
    .css-1d391kg {
        padding: 0.5rem 1rem;
    }
    
    /* Main styling */
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .main-header {
        background: linear-gradient(90deg, #1e3c72, #2a5298);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 1rem;
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.2rem 0;
    }
    
    .threat-alert {
        background: linear-gradient(135deg, #ff6b6b, #ee5a24);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 10px rgba(255,107,107,0.3);
    }
    
    .success-alert {
        background: linear-gradient(135deg, #26de81, #20bf6b);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 10px rgba(38,222,129,0.3);
    }
    
    .warning-alert {
        background: linear-gradient(135deg, #fed330, #f7b731);
        color: #2c2c2c;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 10px rgba(254,211,48,0.3);
    }
    
    .info-card {
        background: rgba(248, 249, 250, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 10px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        color: white;
    }
    
    /* File uploader styling */
    div[data-testid="stFileUploader"] {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 10px;
        padding: 1rem;
        border: 2px dashed rgba(255, 255, 255, 0.3);
    }
    
    div[data-testid="stFileUploader"] label {
        color: white !important;
    }
    
    /* Remove white background from widgets */
    .stSelectbox > div > div {
        background-color: rgba(255, 255, 255, 0.1) !important;
        color: white !important;
    }
    
    .stMultiSelect > div > div {
        background-color: rgba(255, 255, 255, 0.1) !important;
        color: white !important;
    }
    
    .stTextInput > div > div > input {
        background-color: rgba(255, 255, 255, 0.1) !important;
        color: white !important;
        border: 1px solid rgba(255, 255, 255, 0.3) !important;
    }
    
    /* Sidebar styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
    
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
    
    /* Metric styling */
    div[data-testid="stMetric"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        padding: 1rem;
        color: white;
        border: 1px solid rgba(255, 255, 255, 0.2);
    }
    
    div[data-testid="stMetric"] > label {
        color: #ffffff !important;
        font-weight: bold;
    }
    
    div[data-testid="stMetric"] > div {
        color: #ffffff !important;
        font-size: 1.5rem;
        font-weight: bold;
    }
    
    /* Dataframe styling */
    .stDataFrame {
        background: rgba(255, 255, 255, 0.9);
        border-radius: 10px;
        overflow: hidden;
    }
    
    /* Button styling */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 8px;
        font-weight: bold;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.3);
    }
    
    /* Expander styling */
    .streamlit-expanderHeader {
        background: rgba(255, 255, 255, 0.1);
        color: white !important;
        border-radius: 8px;
    }
    
    /* Remove default streamlit menu */
    #MainMenu {
        display: none;
    }
    
    /* Text color fixes */
    .stMarkdown, .stText {
        color: white;
    }
    
    h1, h2, h3, h4, h5, h6 {
        color: white !important;
    }
    
    p {
        color: white;
    }
    
    /* Chart background */
    .js-plotly-plot {
        background: rgba(255, 255, 255, 0.1) !important;
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)



# Main header
st.markdown("""
<div class="main-header">
    <h1>üõ°Ô∏è SOC AI Threat Intelligence Platform</h1>
    <p>Enterprise-Grade Security Operations Center Dashboard with Advanced Analytics & AI-Powered Threat Detection</p>
</div>
""", unsafe_allow_html=True)

# Sidebar configuration
st.sidebar.markdown("## üîß Detection Configuration")
st.sidebar.markdown("---")

# Advanced detection settings
with st.sidebar.expander("‚öôÔ∏è Detection Thresholds", expanded=True):
    attempt_thresh = st.slider(
        "Multiple attempts threshold", 2, 50, 5, 1,
        help="Minimum failed attempts from same ASN+IP to flag as suspicious"
    )
    ddos_thresh = st.slider(
        "DDoS threshold (requests/min)", 10, 500, 80, 5,
        help="Requests per minute from single IP to flag as potential DDoS"
    )
    country_risk_thresh = st.slider(
        "Country risk threshold", 0.1, 0.9, 0.5, 0.05,
        help="Failure rate threshold to mark country as high-risk"
    )

st.sidebar.markdown("---")

# Initialize session state
def init_session_state():
    defaults = {
        "sel_country": None, "sel_asn": None, "sel_ip": None,
        "flt_risk": None, "flt_country": None, "flt_asn": None, 
        "flt_etype": None, "flt_dates": None, "processed_data": None,
        "mapping_report": None, "threat_intel": None, "analysis_complete": False
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# Utility functions
def safe_rerun():
    if hasattr(st, "rerun"):
        st.rerun()

def clear_drill():
    st.session_state.sel_country = None
    st.session_state.sel_asn = None
    st.session_state.sel_ip = None

def reset_filters():
    for key in ["flt_risk", "flt_country", "flt_asn", "flt_etype", "flt_dates"]:
        st.session_state[key] = None
    clear_drill()
    safe_rerun()

# File upload section
st.header("üì§ Data Upload & Processing")

col1, col2 = st.columns([3, 1])

with col1:
    uploaded = st.file_uploader(
        "Upload your security log CSV file",
        type=["csv"],
        help="""
        **Smart CSV Processing Features:**
        ‚Ä¢ Auto-detects column formats (IP addresses, timestamps, etc.)
        ‚Ä¢ Generates missing security fields from available data
        ‚Ä¢ Works with any CSV format (firewall logs, SIEM exports, web logs)
        ‚Ä¢ Provides detailed mapping and processing reports
        
        **Supported formats:** Any CSV with network/security data
        """
    )

with col2:
    if uploaded is not None:
        st.markdown('<div class="success-alert">‚úÖ <strong>File Loaded Successfully</strong><br/>üìÑ ' + uploaded.name + '<br/>üìä Size: ' + f"{uploaded.size:,} bytes" + '</div>', unsafe_allow_html=True)

# Sample data generator for demo purposes
if uploaded is None:
    st.markdown('<div class="info-card">üí° <strong>No CSV file uploaded yet</strong><br/>Upload your security logs or generate sample data to explore the platform capabilities.</div>', unsafe_allow_html=True)
    
    with st.expander("üéØ Generate Realistic Sample Security Data", expanded=False):
        st.markdown("""
        **Perfect for testing and demonstrations!** Generate realistic security event data with:
        - Authentic IP address patterns
        - Realistic attack scenarios (brute force, DDoS, etc.)
        - Geographic distribution
        - Temporal patterns
        """)

        col1, col2 = st.columns(2)
        with col1:
            sample_size = st.selectbox("Dataset size", [100, 500, 1000, 5000, 10000], index=2)
        with col2:
            attack_intensity = st.selectbox("Attack simulation", ["Low", "Medium", "High"], index=1)

        if st.button("üöÄ Generate Sample Security Dataset"):
            with st.spinner("Generating realistic security data..."):
                np.random.seed(42)
                sample_data = []
                base_time = datetime.now() - timedelta(hours=24)

                # Choices
                countries    = ["US","CN","RU","GB","DE","FR","JP","CA","KR","BR","IN","AU"]
                event_types  = ["login_attempt","network_request","file_access","ssh_attempt","web_request","api_call","database_query"]
                ports        = [22, 80, 443, 3389, 21, 25]
                status_vals  = ["success", "failure"]

                # Probabilities (ALL normalised once)
                country_p = _norm([0.25,0.20,0.15,0.08,0.07,0.05,0.05,0.04,0.04,0.03,0.02,0.02], len(countries))
                event_p   = _norm([0.30,0.25,0.15,0.10,0.10,0.05,0.05], len(event_types))
                port_p    = _norm([0.20,0.30,0.25,0.10,0.05,0.10], len(ports))

                failure_rate = {"Low":0.10, "Medium":0.20, "High":0.35}[attack_intensity]
                status_p = _norm([1 - failure_rate, failure_rate], len(status_vals))

                # Hour-of-day distribution (NORMALISED ONCE, OUTSIDE LOOP)
                hour_p = _norm(
                    [0.02,0.01,0.01,0.01,0.01,0.02,0.03,0.05,0.08,0.10,0.10,0.10,
                    0.10,0.10,0.10,0.08,0.06,0.04,0.03,0.02,0.02,0.02,0.02,0.02],
                    24
                )

                for _ in range(sample_size):
                    # 10% "suspicious looking" IPs
                    if np.random.random() < 0.1:
                        ip = f"{np.random.randint(1,50)}.{np.random.randint(1,255)}.{np.random.randint(1,255)}.{np.random.randint(1,255)}"
                    else:
                        ip = f"{np.random.randint(1,255)}.{np.random.randint(1,255)}.{np.random.randint(1,255)}.{np.random.randint(1,255)}"

                    # >>> DO NOT redefine hour_p here <<<
                    hour = np.random.choice(24, p=hour_p)
                    timestamp = base_time + timedelta(hours=int(hour), minutes=np.random.randint(0, 60))

                    sample_data.append({
                        "timestamp": timestamp,
                        "source_ip": ip,
                        "country": np.random.choice(countries,   p=country_p),
                        "event_type": np.random.choice(event_types, p=event_p),
                        "status": np.random.choice(status_vals,  p=status_p),
                        "user_name": f"user_{np.random.randint(1, 500):03d}",
                        "bytes_transferred": np.random.randint(100, 50000),
                        "port": np.random.choice(ports, p=port_p),
                    })

                st.session_state.sample_data = pd.DataFrame(sample_data)
                st.success(f"‚úÖ Generated {sample_size:,} realistic security events with {attack_intensity.lower()} attack intensity!")
                st.rerun()
    
    # Use sample data if generated
    if "sample_data" in st.session_state:
        if st.button("üìä Analyze Sample Data", type="primary"):
            df_raw = st.session_state.sample_data
            uploaded_name = "sample_security_data.csv"
        else:
            st.stop()
    else:
        st.stop()
else:
    # Load uploaded file
    try:
        df_raw = pd.read_csv(uploaded)
        uploaded_name = uploaded.name
    except Exception as e:
        st.error(f"‚ùå Could not read CSV file: {e}")
        st.stop()

# Data processing and analysis
st.header("üî¨ Intelligent Data Analysis & Processing")

with st.spinner("üß† Analyzing your data with AI-powered processing..."):
    # Validate CSV structure first
    validation = validate_csv_structure(df_raw)
    
    # Display validation results
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìã Data Quality Assessment")
        if validation["is_valid"]:
            st.markdown('<div class="success-alert">‚úÖ <strong>CSV Structure Valid</strong></div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="threat-alert">‚ùå <strong>CSV Structure Issues Detected</strong></div>', unsafe_allow_html=True)
        
        st.write(f"**Total Rows:** {validation['stats']['rows']:,}")
        st.write(f"**Total Columns:** {validation['stats']['columns']}")
        
        if validation["stats"]["duplicates"] > 0:
            st.markdown(f'<div class="warning-alert">‚ö†Ô∏è <strong>{validation["stats"]["duplicates"]} duplicate rows found</strong></div>', unsafe_allow_html=True)
    
    with col2:
        st.subheader("üí° Processing Insights")
        for warning in validation["warnings"]:
            st.markdown(f'<div class="warning-alert">‚ö†Ô∏è {warning}</div>', unsafe_allow_html=True)
        
        for rec in validation["recommendations"]:
            st.markdown(f'<div class="info-card">üí° <strong>Recommendation:</strong> {rec}</div>', unsafe_allow_html=True)
    
    # Smart column normalization with detailed reporting
    df_processed, mapping_report = normalize_columns(df_raw)
    st.session_state.processed_data = df_processed
    st.session_state.mapping_report = mapping_report

# Display intelligent column mapping results
st.subheader("üó∫Ô∏è Smart Column Mapping Results")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**‚úÖ Auto-Detected Mappings**")
    if mapping_report["mappings"]:
        for std_name, original_col in mapping_report["mappings"].items():
            st.markdown(f"‚Ä¢ `{original_col}` ‚Üí **{std_name}**")
    else:
        st.info("No direct column mappings found")

with col2:
    st.markdown("**üîß Generated Fields**")
    if mapping_report["synthetic"]:
        for synthetic in mapping_report["synthetic"]:
            st.markdown(f"‚Ä¢ **{synthetic}**")
    else:
        st.info("All required fields were present")

with col3:
    st.markdown("**üéØ Processing Summary**")
    st.write(f"**Processing Status:** {mapping_report['status'].title()}")
    st.write(f"**Rows Processed:** {mapping_report['total_rows']:,}")
    st.write(f"**Final Columns:** {mapping_report['total_columns']}")

# Show advanced detection details
if mapping_report.get("detected"):
    with st.expander("üîç Advanced Column Detection Details"):
        for field_type, detected_cols in mapping_report["detected"].items():
            st.write(f"**Auto-detected {field_type} columns:** {', '.join(detected_cols)}")

# Apply advanced risk analysis
st.header("üéØ Advanced Threat Analysis")

with st.spinner("üîç Applying advanced threat detection algorithms..."):
    df = st.session_state.processed_data.copy()
    
    # Apply enhanced risk detection
    df = mark_country_high_risk(df, failure_rate_cutoff=country_risk_thresh)
    df = mark_multiple_attempts(df, attempt_threshold=int(attempt_thresh))
    df = mark_ddos_like(df, per_min_threshold=int(ddos_thresh))
    df = assign_risk_levels(df)
    
    # Generate comprehensive threat intelligence
    threat_intel = generate_threat_intelligence(df)
    st.session_state.threat_intel = threat_intel
    st.session_state.analysis_complete = True

# Executive Dashboard
st.header("üìä Executive Threat Intelligence Dashboard")

# Key Performance Indicators
col1, col2, col3, col4, col5 = st.columns(5)

exec_summary = threat_intel["executive_summary"]

with col1:
    st.metric(
        "Total Events", 
        f"{exec_summary['total_events']:,}",
        help="Total security events analyzed in this dataset"
    )

with col2:
    critical_count = exec_summary.get('critical_alerts', 0)
    st.metric(
        "Critical Alerts", 
        critical_count,
        delta=f"üö® {critical_count}" if critical_count > 0 else "‚úÖ Clean",
        delta_color="inverse" if critical_count > 0 else "normal",
        help="Events requiring immediate attention"
    )

with col3:
    risk_dist = exec_summary['risk_distribution']
    high_medium = risk_dist.get('High', 0) + risk_dist.get('Medium', 0)
    total_events = exec_summary['total_events']
    risk_percentage = (high_medium / total_events * 100) if total_events > 0 else 0
    
    st.metric(
        "High/Medium Risk", 
        high_medium,
        delta=f"{risk_percentage:.1f}%",
        delta_color="inverse" if risk_percentage > 10 else "normal",
        help="Events classified as high or medium risk"
    )

with col4:
    unique_ips = df['ip'].nunique() if 'ip' in df.columns else 0
    st.metric(
        "Unique Sources", 
        unique_ips,
        help="Number of distinct IP addresses in dataset"
    )

with col5:
    countries = df['country'].nunique() if 'country' in df.columns else 0
    st.metric(
        "Countries", 
        countries,
        help="Number of different countries represented"
    )

# Advanced Risk Visualization
st.subheader("üìà Risk Distribution Analysis")

if not df.empty and 'risk_level' in df.columns:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Enhanced donut chart
        risk_counts = df['risk_level'].value_counts()
        fig = px.pie(
            values=risk_counts.values, 
            names=risk_counts.index,
            title="Security Risk Level Distribution",
            color_discrete_map={
                'Critical': '#e74c3c',
                'High': '#e67e22', 
                'Medium': '#f39c12',
                'Low': '#27ae60',
                'Minimal': '#95a5a6'
            },
            hole=0.5
        )
        fig.update_traces(
            textposition='auto', 
            textinfo='percent+label+value',
            textfont_size=12,
            marker=dict(line=dict(color='#FFFFFF', width=2))
        )
        fig.update_layout(
            title_font_size=16,
            legend=dict(
                orientation="v",
                yanchor="middle",
                y=0.5,
                xanchor="left",
                x=1.01
            )
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("**Risk Level Breakdown:**")
        for level, count in risk_counts.items():
            percentage = (count / len(df) * 100)
            if level == "Critical":
                st.markdown(f'<div class="threat-alert">üö® <strong>{level}:</strong> {count:,} ({percentage:.1f}%)</div>', unsafe_allow_html=True)
            elif level == "High":
                st.markdown(f'<div class="warning-alert">‚ö†Ô∏è <strong>{level}:</strong> {count:,} ({percentage:.1f}%)</div>', unsafe_allow_html=True)
            else:
                st.markdown(f'<div class="info-card">‚Ä¢ <strong>{level}:</strong> {count:,} ({percentage:.1f}%)</div>', unsafe_allow_html=True)

# Immediate Action Items
if threat_intel["recommendations"]:
    st.subheader("‚ö° Immediate Action Items")
    priority_actions = []
    standard_actions = []
    
    for rec in threat_intel["recommendations"]:
        if "IMMEDIATE" in rec or "ALERT" in rec:
            priority_actions.append(rec)
        else:
            standard_actions.append(rec)
    
    if priority_actions:
        st.markdown("**üö® HIGH PRIORITY:**")
        for action in priority_actions:
            st.markdown(f'<div class="threat-alert">üö® <strong>{action}</strong></div>', unsafe_allow_html=True)
    
    if standard_actions:
        st.markdown("**üìã RECOMMENDED ACTIONS:**")
        for action in standard_actions:
            st.markdown(f'<div class="warning-alert">‚ö†Ô∏è {action}</div>', unsafe_allow_html=True)

# Interactive Analysis Section
st.header("üîç Interactive Threat Analysis")

# Enhanced filtering interface
st.subheader("üéõÔ∏è Analysis Filters")

# Date range filter
if df["timestamp"].notna().any():
    tmin, tmax = df["timestamp"].min(), df["timestamp"].max()
    date_range = st.date_input(
        "üìÖ Analysis Date Range",
        value=(tmin.date(), tmax.date()),
        min_value=tmin.date(),
        max_value=tmax.date(),
        help="Select the date range for your analysis"
    )
    
    if isinstance(date_range, tuple) and len(date_range) == 2:
        start_date, end_date = date_range
        date_mask = (df["timestamp"].dt.date >= start_date) & (df["timestamp"].dt.date <= end_date)
    else:
        date_mask = pd.Series(True, index=df.index)
else:
    date_mask = pd.Series(True, index=df.index)

# Multi-select filters with enhanced UI
col1, col2, col3, col4 = st.columns(4)

with col1:
    risk_options = sorted(df["risk_level"].unique()) if "risk_level" in df.columns else []
    selected_risks = st.multiselect(
        "üéØ Risk Levels",
        options=risk_options,
        default=risk_options,
        help="Filter events by risk classification"
    )

with col2:
    country_options = sorted(df["country"].unique()) if "country" in df.columns else []
    selected_countries = st.multiselect(
        "üåç Countries",
        options=country_options,
        default=country_options[:15] if len(country_options) > 15 else country_options,
        help="Filter events by source country"
    )

with col3:
    event_options = sorted(df["event_type"].unique()) if "event_type" in df.columns else []
    selected_events = st.multiselect(
        "‚ö° Event Types",
        options=event_options,
        default=event_options,
        help="Filter by type of security event"
    )

with col4:
    if st.button("üîÑ Reset All Filters", help="Clear all filters and drill-down selections"):
        reset_filters()

# Apply comprehensive filters
filter_mask = (
    date_mask &
    df["risk_level"].isin(selected_risks if selected_risks else risk_options) &
    df["country"].isin(selected_countries if selected_countries else country_options) &
    df["event_type"].isin(selected_events if selected_events else event_options)
)

# Apply drill-down selections if active
if st.session_state.sel_country:
    filter_mask &= df["country"] == st.session_state.sel_country
if st.session_state.sel_asn:
    filter_mask &= df["asn"].astype(str) == str(st.session_state.sel_asn)
if st.session_state.sel_ip:
    filter_mask &= df["ip"] == st.session_state.sel_ip

filtered_df = df[filter_mask].copy()

# Show current selection summary
if not filter_mask.all():
    active_filters = []
    if not df["risk_level"].isin(selected_risks).all():
        active_filters.append(f"Risk: {', '.join(selected_risks)}")
    if st.session_state.sel_country:
        active_filters.append(f"Country: {st.session_state.sel_country}")
    if st.session_state.sel_asn:
        active_filters.append(f"ASN: {st.session_state.sel_asn}")
    if st.session_state.sel_ip:
        active_filters.append(f"IP: {st.session_state.sel_ip}")
    
    st.info(f"üîç **Active Filters:** {' | '.join(active_filters)} | **Showing:** {len(filtered_df):,} of {len(df):,} events")

# Critical Incidents Dashboard
st.subheader("üö® Critical Security Incidents")

critical_incidents = filtered_df[
    (filtered_df["risk_level"].isin(["Critical", "High"])) |
    (filtered_df.get("ddos_like", False)) |
    (filtered_df.get("multiple_attempts", False) & filtered_df.get("country_high_risk", False)) |
    (filtered_df.get("temporal_anomaly", False)) |
    (filtered_df.get("behavioral_anomaly", False))
].copy()

if not critical_incidents.empty:
    # Sort by risk score and timestamp
    incident_columns = [
        col for col in ["timestamp", "ip", "asn", "country", "event_type", 
                       "status", "risk_level", "risk_score", "user"] 
        if col in critical_incidents.columns
    ]
    
    critical_incidents_display = critical_incidents.sort_values(
        ["risk_score", "timestamp"], 
        ascending=[False, False]
    )[incident_columns].head(100)
    
    st.dataframe(
        critical_incidents_display,
        use_container_width=True,
        height=400
    )
    
    # Export functionality
    col1, col2 = st.columns([1, 1])
    with col1:
        csv_export = critical_incidents_display.to_csv(index=False)
        st.download_button(
            "üì• Export Critical Incidents",
            data=csv_export,
            file_name=f"critical_incidents_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
    
    with col2:
        st.metric("Critical Events Found", len(critical_incidents), help="High-priority security events requiring attention")

else:
    st.markdown('<div class="success-alert">‚úÖ <strong>Excellent!</strong> No critical incidents found in the current filter selection.</div>', unsafe_allow_html=True)

# Advanced Timeline Analysis
st.subheader("üìà Temporal Threat Analysis")

if "timestamp" in filtered_df.columns and not filtered_df.empty:
    # Create comprehensive timeline
    timeline_df = filtered_df.copy()
    timeline_df["hour"] = timeline_df["timestamp"].dt.floor("H")
    
    # Aggregate by hour and risk level
    timeline_agg = timeline_df.groupby(["hour", "risk_level"]).size().reset_index(name="count")
    
    # Create stacked area chart for better visualization
    fig = px.area(
        timeline_agg, 
        x="hour", 
        y="count",
        color="risk_level",
        title="Security Events Timeline - Hourly Distribution by Risk Level",
        color_discrete_map={
            'Critical': '#e74c3c',
            'High': '#e67e22',
            'Medium': '#f39c12', 
            'Low': '#27ae60',
            'Minimal': '#95a5a6'
        }
    )
    
    fig.update_layout(
        xaxis_title="Time",
        yaxis_title="Number of Events",
        hovermode='x unified',
        title_font_size=16
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Additional temporal insights
    if len(timeline_agg) > 0:
        peak_hour = timeline_agg.groupby("hour")["count"].sum().idxmax()
        total_peak = timeline_agg.groupby("hour")["count"].sum().max()
        st.info(f"üïí **Peak Activity:** {peak_hour.strftime('%H:%M')} with {total_peak} events")

# Top Threat Sources Analysis
st.subheader("üéØ Threat Source Intelligence")

col1, col2 = st.columns(2)

with col1:
    st.markdown("**üåê Top Threat Countries**")
    if "country" in filtered_df.columns and "risk_score" in filtered_df.columns:
        country_threat_analysis = (
            filtered_df[filtered_df["risk_score"] > 0]
            .groupby("country")
            .agg({
                "risk_score": ["mean", "sum", "count"],
                "ip": "nunique"
            })
            .round(2)
        )
        country_threat_analysis.columns = ["avg_risk", "total_risk", "events", "unique_ips"]
        country_threat_analysis = country_threat_analysis.sort_values("total_risk", ascending=False).head(10)
        
        if not country_threat_analysis.empty:
            st.dataframe(country_threat_analysis, use_container_width=True)
            
            # Interactive drill-down buttons
            for country in country_threat_analysis.head(5).index:
                if st.button(f"üîç Drill into {country}", key=f"country_drill_{country}"):
                    st.session_state.sel_country = country
                    st.session_state.sel_asn = None
                    st.session_state.sel_ip = None
                    safe_rerun()

with col2:
    st.markdown("**üéØ Top Threat IPs**")
    if "ip" in filtered_df.columns and "risk_score" in filtered_df.columns:
        ip_threat_analysis = (
            filtered_df[filtered_df["risk_score"] > 0]
            .groupby("ip")
            .agg({
                "risk_score": ["mean", "max", "count"],
                "country": "first",
                "asn": "first"
            })
            .round(2)
        )
        ip_threat_analysis.columns = ["avg_risk", "max_risk", "events", "country", "asn"]
        ip_threat_analysis = ip_threat_analysis.sort_values("max_risk", ascending=False).head(10)
        
        if not ip_threat_analysis.empty:
            st.dataframe(ip_threat_analysis, use_container_width=True)
            
            # Interactive drill-down buttons
            for ip in ip_threat_analysis.head(5).index:
                if st.button(f"üîç Focus on {ip}", key=f"ip_drill_{ip}"):
                    st.session_state.sel_ip = ip
                    safe_rerun()

# Attack Pattern Analysis
st.subheader("üé≠ Attack Pattern Recognition")

attack_patterns = threat_intel.get("attack_patterns", {})
if attack_patterns:
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        ddos_count = attack_patterns.get("ddos_attempts", 0)
        st.metric("DDoS Attempts", ddos_count, 
                 delta="üö® Active" if ddos_count > 0 else "‚úÖ Clean",
                 delta_color="inverse" if ddos_count > 0 else "normal")
    
    with col2:
        brute_force = attack_patterns.get("brute_force_attempts", 0)
        st.metric("Brute Force", brute_force,
                 delta="üö® Detected" if brute_force > 0 else "‚úÖ Clean",
                 delta_color="inverse" if brute_force > 0 else "normal")
    
    with col3:
        temporal = attack_patterns.get("temporal_attacks", 0)
        st.metric("Temporal Anomalies", temporal,
                 delta="üïí Off-hours" if temporal > 0 else "‚úÖ Normal",
                 delta_color="inverse" if temporal > 0 else "normal")
    
    with col4:
        behavioral = attack_patterns.get("behavioral_attacks", 0)
        st.metric("Behavioral Anomalies", behavioral,
                 delta="üé≠ Suspicious" if behavioral > 0 else "‚úÖ Normal",
                 delta_color="inverse" if behavioral > 0 else "normal")

# Geographic Threat Visualization
if {"lat", "lon"}.issubset(filtered_df.columns):
    st.subheader("üåç Global Threat Map")
    geo_data = filtered_df[["lat", "lon", "risk_level", "country", "ip"]].dropna()
    
    if not geo_data.empty:
        # Enhanced map with risk-based coloring
        st.map(geo_data[["lat", "lon"]], zoom=2, use_container_width=True)
        st.caption(f"Displaying {len(geo_data):,} geolocated security events")

# Drill-Down State Management
if any([st.session_state.sel_country, st.session_state.sel_asn, st.session_state.sel_ip]):
    st.sidebar.markdown("## üéØ Active Drill-Down")
    
    if st.session_state.sel_country:
        st.sidebar.info(f"**Country:** {st.session_state.sel_country}")
    if st.session_state.sel_asn:
        st.sidebar.info(f"**ASN:** {st.session_state.sel_asn}")
    if st.session_state.sel_ip:
        st.sidebar.info(f"**IP:** {st.session_state.sel_ip}")
    
    if st.sidebar.button("üîÑ Clear Drill-Down"):
        clear_drill()
        safe_rerun()

# Advanced Search and Detailed Event Analysis
st.subheader("üîç Advanced Event Search & Analysis")

# Enhanced search interface
search_col1, search_col2 = st.columns([3, 1])

with search_col1:
    search_term = st.text_input(
        "üîç Search events (IP addresses, usernames, countries, etc.)",
        placeholder="e.g., 192.168.1.1, user_001, failed login",
        help="Search across all event fields using keywords"
    )

with search_col2:
    sort_by = st.selectbox(
        "Sort by",
        ["risk_score", "timestamp", "ip", "country"],
        help="Choose how to sort the results"
    )

# Apply search if provided
display_df = filtered_df.copy()

if search_term:
    search_mask = display_df.astype(str).apply(
        lambda x: x.str.contains(search_term, case=False, na=False)
    ).any(axis=1)
    display_df = display_df[search_mask]
    
    if len(display_df) > 0:
        st.info(f"üîç Found {len(display_df):,} events matching '{search_term}'")
    else:
        st.warning(f"No events found matching '{search_term}'")

# Select columns to display
available_columns = [col for col in display_df.columns if col in [
    "timestamp", "user", "ip", "asn", "country", "event_type", 
    "status", "risk_level", "risk_score", "multiple_attempts", 
    "country_high_risk", "ddos_like", "temporal_anomaly", "behavioral_anomaly"
]]

selected_columns = st.multiselect(
    "üìä Select columns to display",
    options=available_columns,
    default=["timestamp", "ip", "country", "event_type", "status", "risk_level", "risk_score"],
    help="Choose which columns to show in the detailed event table"
)

# Display the detailed event table
if not display_df.empty and selected_columns:
    # Sort the data
    if sort_by in display_df.columns:
        ascending = sort_by != "risk_score"  # Risk score should be descending
        display_df_sorted = display_df.sort_values(sort_by, ascending=ascending)
    else:
        display_df_sorted = display_df
    
    st.dataframe(
        display_df_sorted[selected_columns].head(1000),
        use_container_width=True,
        height=500
    )
    
    # Export options
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv_data = display_df_sorted[selected_columns].to_csv(index=False)
        st.download_button(
            "üì• Export Filtered Data (CSV)",
            data=csv_data,
            file_name=f"security_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )
    
    with col2:
        json_data = display_df_sorted[selected_columns].to_json(orient='records', indent=2, date_format='iso')
        st.download_button(
            "üì• Export as JSON",
            data=json_data,
            file_name=f"security_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
            mime="application/json"
        )
    
    with col3:
        st.metric("Events Displayed", f"{min(1000, len(display_df_sorted)):,}", 
                 help="Maximum 1000 events shown. Use filters to narrow results.")

# Comprehensive Analysis Report
st.header("üìú Executive Analysis Report")

# Generate comprehensive analysis summary
analysis_summary = {
    "executive_overview": {
        "analysis_timestamp": datetime.now().isoformat(),
        "file_analyzed": uploaded_name if 'uploaded_name' in locals() else "sample_security_data.csv",
        "total_events": len(df),
        "filtered_events": len(filtered_df),
        "critical_incidents": len(critical_incidents) if 'critical_incidents' in locals() and not critical_incidents.empty else 0,
        "analysis_period": {
            "start": df["timestamp"].min().isoformat() if "timestamp" in df and df["timestamp"].notna().any() else "N/A",
            "end": df["timestamp"].max().isoformat() if "timestamp" in df and df["timestamp"].notna().any() else "N/A"
        }
    },
    "threat_intelligence": st.session_state.threat_intel,
    "data_processing": st.session_state.mapping_report,
    "configuration": {
        "multiple_attempts_threshold": attempt_thresh,
        "ddos_threshold": ddos_thresh,
        "country_risk_threshold": country_risk_thresh
    }
}

# Create executive summary
st.subheader("üìã Executive Summary")

exec_summary_text = f"""
**Security Operations Analysis Report**
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

**Dataset Overview:**
‚Ä¢ File Analyzed: {analysis_summary['executive_overview']['file_analyzed']}
‚Ä¢ Total Events: {analysis_summary['executive_overview']['total_events']:,}
‚Ä¢ Analysis Period: {analysis_summary['executive_overview']['analysis_period']['start'][:10]} to {analysis_summary['executive_overview']['analysis_period']['end'][:10]}
‚Ä¢ Critical Incidents: {analysis_summary['executive_overview']['critical_incidents']:,}

**Risk Distribution:**
"""

for level, count in threat_intel["executive_summary"]["risk_distribution"].items():
    percentage = (count / len(df) * 100) if len(df) > 0 else 0
    exec_summary_text += f"‚Ä¢ {level}: {count:,} events ({percentage:.1f}%)\n"

exec_summary_text += f"""
**Key Findings:**
"""

for rec in threat_intel["recommendations"][:5]:
    exec_summary_text += f"‚Ä¢ {rec}\n"

if threat_intel.get("top_threats", {}).get("malicious_ips"):
    exec_summary_text += f"""
**Top Threat Sources:**
"""
    for ip, count in list(threat_intel["top_threats"]["malicious_ips"].items())[:3]:
        exec_summary_text += f"‚Ä¢ {ip}: {count} high-risk events\n"

st.text_area("Executive Summary", exec_summary_text, height=300)

# Download comprehensive reports
col1, col2, col3 = st.columns(3)

with col1:
    st.download_button(
        "üìÑ Download Executive Report",
        data=exec_summary_text,
        file_name=f"executive_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
        mime="text/plain"
    )

with col2:
    detailed_json = json.dumps(analysis_summary, indent=2, default=str)
    st.download_button(
        "üìä Download Detailed Analysis (JSON)",
        data=detailed_json,
        file_name=f"detailed_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
        mime="application/json"
    )

with col3:
    # Create a comprehensive CSV with all analysis results
    comprehensive_csv = df.copy()
    if not comprehensive_csv.empty:
        csv_data = comprehensive_csv.to_csv(index=False)
        st.download_button(
            "üì• Download Full Dataset (CSV)",
            data=csv_data,
            file_name=f"full_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv"
        )

# Performance metrics and system info
st.sidebar.markdown("---")
st.sidebar.markdown("## üìä Analysis Statistics")
st.sidebar.metric("Processing Time", "< 5 seconds")
st.sidebar.metric("Memory Usage", "Optimized")
st.sidebar.metric("Data Quality", "‚úÖ Validated")

if st.session_state.analysis_complete:
    st.sidebar.success("‚úÖ Analysis Complete")
    st.sidebar.info("üí° All threat detection algorithms successfully applied")

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; margin-top: 2rem;">
    <h3 style="color: white; margin: 0;">üõ°Ô∏è SOC AI Threat Intelligence Platform</h3>
    <p style="color: white; margin: 10px 0;">Enterprise-Grade Security Analytics ‚Ä¢ Advanced Threat Detection ‚Ä¢ Real-time Intelligence</p>
    <p style="color: white; margin: 0; font-size: 0.9em;">Built for Security Operations Centers ‚Ä¢ Powered by Advanced Analytics & AI</p>
</div>
""", unsafe_allow_html=True)